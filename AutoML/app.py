# %%
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os

import pandas as pd
from sklearn.model_selection import train_test_split

import streamlit as st
import streamlit.components.v1 as components

import mlflow

import pygwalker as pyg
import sweetviz as sv

from pycaret.datasets import get_data
from pycaret.classification import ClassificationExperiment
from pycaret.regression import RegressionExperiment
from pycaret.time_series import TSForecastingExperiment
from pycaret.clustering import ClusteringExperiment
from pycaret.anomaly import AnomalyExperiment

from autogluon.tabular import TabularDataset, TabularPredictor
from autogluon.multimodal import MultiModalPredictor

import h2o
# %%
# å„ç¨®ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°
@st.cache_data
def get_sweetviz_result(df_data):
    report = sv.analyze(df_data, pairwise_analysis="off")
    report.show_html("eda.html", open_browser=False, layout="widescreen", scale=0.9)
    with open('eda.html', encoding='utf-8') as f:
        html = f.read()
    return html

@st.cache_data
def get_pycaret_model_result(_s):
    best = _s.compare_models()
    results = _s.pull()
    return best, results

@st.cache_data
def get_pycaret_predict_result(_best):
    predict = s.predict_model(_best)
    return predict

@st.cache_data
def get_deepchecks_result(_best):
    report = s.deep_check(_best, check_kwargs={})
    report.save_as_html('deepchecks.html')
    with open('deepchecks.html', encoding='utf-8') as f:
        html = f.read()
    os.remove('deepchecks.html')
    return html
# %%
# ãƒšãƒ¼ã‚¸å…¨ä½“ã®è¨­å®š
st.set_page_config(layout="wide")
st.title('AutoML playground')

# åˆæœŸã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®ä¿å­˜
if 'init' not in st.session_state:
    st.session_state['init'] = True
    st.session_state['index'] = get_data('index')
    st.session_state['data_list'] = {}
    st.session_state['data_list']['iris'] = get_data('iris')
    st.session_state['analysis_list'] = {}
    st.session_state['plot_model'] = pd.read_csv('plot_model.csv', encoding='cp932')
# %%
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header('1. ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ')
uploaded_file = st.sidebar.file_uploader(label='ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰', label_visibility='collapsed')
if uploaded_file is not None:
    st.session_state['data_list'][uploaded_file.name] = pd.read_csv(uploaded_file)

st.sidebar.header('2. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆä»»æ„ï¼‰')
if st.sidebar.button(label='è©³ç´°ã‚’ç¢ºèª'):
    st.write(st.session_state['index'])
sample_data = st.sidebar.selectbox(
    label='ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠ',
    options=list(st.session_state['index']['Dataset']), 
    label_visibility='collapsed',
    )
if st.sidebar.button(label='è¿½åŠ '):
    st.session_state['data_list'][sample_data] = get_data(sample_data)

st.sidebar.header('3. åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠ')
select_data = st.sidebar.radio(
    label='åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠ',
    options=list(st.session_state['data_list'].keys()),
    horizontal=True,
    label_visibility='collapsed',
    )

st.sidebar.download_button(
    label="ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆoptionï¼‰",
    data=st.session_state['data_list'][select_data].to_csv(index=False).encode('utf-8'),
    file_name=f"{select_data}.csv",
    mime="text/csv",
    key='download-csv',
)
if st.sidebar.button(label='åˆ†æé–‹å§‹'):
    st.session_state['analysis_list'][select_data] = select_data
# %%
# ãƒšãƒ¼ã‚¸å…¨ä½“ã®è¨­å®š
if select_data in st.session_state['analysis_list'].keys():
    df_data = st.session_state['data_list'][select_data]
    # å¤‰æ•°ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ
    set_col1, set_col2, set_col3, set_col4 = st.columns(4)
    with set_col1:
        target_col = st.selectbox(label="targetåˆ—ã‚’é¸æŠ",options=df_data.columns)
    with set_col2:
        ml_task = st.radio(
            label='ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ',
            options=['Classification','Regression','Time Series','Clustering','Anomaly Detection'],
            horizontal=True
            )
    with set_col3:
        train_size = st.number_input(label='å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ', min_value=0.0, max_value=1.0, value=0.7)
    with set_col4:
        time_limit = st.number_input(label='å­¦ç¿’æ™‚é–“ã®ä¸Šé™ï¼ˆå˜ä½ï¼šåˆ†ã€‚0ã®å ´åˆã¯ç„¡åˆ¶é™ï¼‰', min_value=0)
        if time_limit==0:
            time_limit = None
        st.write(time_limit)
    # ã‚¿ãƒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ•µâ€â™‚ï¸PyGWalker(EDA)", 
        "ğŸ•µâ€â™‚ï¸Sweetviz(EDA)", 
        "ğŸ‘¨ğŸ»â€ğŸ’»PyCaret(AutoML)",
        "ğŸ‘¨ğŸ»â€ğŸ’»AutoGluon(AutoML)",
        "ğŸ‘¨ğŸ»â€ğŸ’»H2O(AutoML)",
        "ğŸ‘¨ğŸ»â€ğŸ’»auto-sklearn(AutoML)",
        ])

    # PyGWalker
    with tab1:
        if st.button("PyGWalker"):
            st.session_state['PyGWalker'] = True
        if 'PyGWalker' in st.session_state:
            pyg.walk(df_data, env='Streamlit')

    # Sweetviz
    with tab2:
        if st.button("Sweetviz"):
            st.session_state['Sweetviz'] = get_sweetviz_result(df_data)
        if 'Sweetviz' in st.session_state:
            components.html(st.session_state['Sweetviz'], height=800, scrolling=True)

    # PyCaret
    with tab3:
        # å¤‰æ•°ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ
        set_col1, set_col2, set_col3 = st.columns(3)
        with set_col1:
            fold_strategy = st.radio(label='CVã‚’é¸æŠ', options=['kfold','groupkfold','timeseries'], horizontal=True)
            if fold_strategy=='groupkfold':
                fold_groups = st.selectbox(label="groupsåˆ—ã‚’é¸æŠ", options=df_data.columns)
            else:
                fold_groups = None
        with set_col2:
            fold = st.number_input(label='Foldæ•°ã‚’é¸æŠ', min_value=2, value=5)
        with set_col3:
            fold_shuffle = st.radio(label='CVã®ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚’è¡Œã†ã‹', options=[True,False], horizontal=True)

        # è¨ˆç®—å®Ÿè¡Œ
        if st.button('è¨ˆç®—å®Ÿè¡Œ', key='PyCaret_è¨ˆç®—å®Ÿè¡Œ'):
            with st.spinner('PyCaretå®Ÿè¡Œä¸­â€¦'):
                # ã‚¿ã‚¹ã‚¯ã®é¸æŠ
                if ml_task=='Classification':
                    s = ClassificationExperiment()
                if ml_task=='Regression':
                    s = RegressionExperiment()
                if ml_task=='Time Series':
                    s = TSForecastingExperiment()
                if ml_task=='ClusteringExperiment':
                    s = ClusteringExperiment()
                if ml_task=='Anomaly Detection':
                    s = AnomalyExperiment()
                    
                # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
                s.setup(
                    data = df_data,
                    target = target_col, 
                    train_size = train_size,
                    fold_strategy = fold_strategy,
                    fold = fold,
                    fold_shuffle = fold_shuffle,
                    fold_groups = fold_groups,
                    html=False,
                    session_id=0,
                    log_experiment=True, 
                    experiment_name=f'{select_data}_pycaret',
                    log_plots=True,
                    log_profile=True,
                    log_data=True,
                    profile=True,
                    )
                # ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
                best = s.compare_models(budget_time=time_limit)
                results = s.pull()

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®ä¿å­˜
                st.session_state['pycaret_setup'] = s
                st.session_state['best'] = best
                st.session_state['results'] = results

        if 'pycaret_setup' in st.session_state: 
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®èª­è¾¼
            s = st.session_state['pycaret_setup']
            best = st.session_state['best']
            results = st.session_state['results']

            # çµæœå‡ºåŠ›
            pycaret_tab1, pycaret_tab2, pycaret_tab3, pycaret_tab4, pycaret_tab5, pycaret_tab6 = \
            st.tabs([
                'ğŸ“‹ï¸çµæœä¸€è¦§',
                'ğŸ“ˆäºˆæ¸¬çµæœ',
                'ğŸ“Šçµæœå¯è¦–åŒ–',
                'ğŸ”€MLflow',
                'ğŸ‘¨â€ğŸ«Deepchecks(ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ)',
                'ğŸ“°ExplainerDashboard(XAI)'
                ])
            with pycaret_tab1:
                st.write(results)
            with pycaret_tab2:
                st.write('äºˆæ¸¬çµæœï¼ˆæœ€å³åˆ—ã®prediction_label&prediction_scoreï¼‰')
                st.write(get_pycaret_predict_result(best))
            with pycaret_tab3:
                plot_model_list = st.session_state['plot_model']
                plot_list = plot_model_list.loc[plot_model_list['Modules']==ml_task,'ID'].values
                col1, col2 = st.columns([2,1])
                with col1:
                    plot_contents = st.radio(label='å¯è¦–åŒ–é …ç›®ã‚’é¸æŠ', options=plot_list, horizontal=True)
                    st.write(
                        plot_model_list.loc[
                            (plot_model_list['Modules']==ml_task)&
                            (plot_model_list['ID']==plot_contents),'Name'].values[0]
                            )
                with col2:
                    try:
                        s.plot_model(best, plot = plot_contents, display_format="streamlit")
                    except Exception as e:
                        st.write(e)
            with pycaret_tab4:
                st.write("ã‚¯ãƒªãƒƒã‚¯ã§åˆ¥çª“è¡¨ç¤ºâ†’[ğŸ”€MLflow](http://localhost:5000/)")
                components.iframe("http://localhost:5000", width=None, height=800, scrolling=True)
            with pycaret_tab5:
                if st.button("Deepchecks"):
                    st.session_state['Deepchecks'] = get_deepchecks_result(best)
                if 'Deepchecks' in st.session_state:
                    components.html(st.session_state['Deepchecks'], height=600, scrolling=True)
            with pycaret_tab6:
                # ExplainerDashboardã¯éšæ™‚ã‚µãƒ¼ãƒãƒ¼ãŒç«‹ã¡ä¸ŠãŒã£ã¦ã—ã¾ã†ã®ã§ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯æ™‚ã®ã¿è¡¨ç¤ºã™ã‚‹
                # TODO:shutdownå®Ÿè£…
                st.write("ExplainerDashboardã‚’èµ·å‹•ã—ã¦ã‹ã‚‰ã‚¯ãƒªãƒƒã‚¯ã§åˆ¥çª“è¡¨ç¤ºâ†’[ğŸ“°ExplainerDashboard](http://localhost:8050/)")
                if st.button('ExplainerDashboardã®èµ·å‹•'):
                    components.iframe("http://localhost:8050", width=None, height=800, scrolling=True)
                    s.dashboard(best)

    # AutoGluon
    with tab4:
        # å¤‰æ•°ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ
        set_col1, set_col2, set_col3 = st.columns(3)
        with set_col1:
            select_presets = st.radio(
                label='presetsã‚’é¸æŠ',
                options=['best_quality', 'high_quality', 'good_quality', 'medium_quality', 'optimize_for_deployment', 'interpretable', 'ignore_text'],
                index=3, # medium_quality
                horizontal=True
                )
        with set_col2:
            tabular_or_multimodel = st.radio(
                label='æ‰±ã†ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ã‚’é¸æŠ',
                options=['è¡¨å½¢å¼','ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«'],
                horizontal=True
                )
        with set_col3:
            if ml_task=='Classification':
                ml_tasks_autogluon = st.radio(label='åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ',options=['binary','multiclass'],horizontal=True)
            if ml_task=='Regression':
                ml_tasks_autogluon = 'regression'
        # è¨ˆç®—å®Ÿè¡Œ
        if st.button(label='è¨ˆç®—å®Ÿè¡Œ', key='AutoGluon_è¨ˆç®—å®Ÿè¡Œ'):
            if time_limit is not None:
                time_limit = int(time_limit*60)
            with st.spinner('AutoGluonå®Ÿè¡Œä¸­â€¦'):
                # ã“ã¡ã‚‰ã®mlflowã¯å‚è€ƒç¨‹åº¦ï¼ˆautologã ã—ã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰
                mlflow.set_experiment(f'{select_data}_autogluon')
                mlflow.autolog()

                train, test = train_test_split(df_data, train_size=train_size, shuffle=True, random_state=0)
                train_data = TabularDataset(train)
                if tabular_or_multimodel=='è¡¨å½¢å¼':
                    predictor = TabularPredictor(label=target_col, problem_type=ml_tasks_autogluon).fit(train_data, presets=select_presets, time_limit=time_limit)
                if tabular_or_multimodel=='ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«':
                    predictor = MultiModalPredictor(label=target_col, problem_type=ml_tasks_autogluon).fit(train_data, presets=select_presets, time_limit=time_limit)
                test_data = TabularDataset(test)
                y_pred = predictor.predict(test_data.drop(columns=[target_col]))
                summary = predictor.fit_summary()
                    
                st.session_state['autogluon_predictor'] = predictor
                st.session_state['autogluon_y_pred'] = y_pred
                st.session_state['autogluon_summary'] = summary
                st.session_state['autogluon_test_data'] = test_data

                if tabular_or_multimodel=='è¡¨å½¢å¼':
                    train_leaderboard = predictor.leaderboard()
                    test_leaderboard = predictor.leaderboard(test_data)
                    st.session_state['train_leaderboard'] = train_leaderboard
                    st.session_state['test_leaderboard'] = test_leaderboard
                
        if 'autogluon_predictor' in st.session_state: 
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®èª­è¾¼
            predictor = st.session_state['autogluon_predictor']
            y_pred = st.session_state['autogluon_y_pred']
            summary = st.session_state['autogluon_summary']
            test_data = st.session_state['autogluon_test_data']

            # çµæœå‡ºåŠ›
            autogluon_tab1, autogluon_tab2 = st.tabs(['ğŸ“‹ï¸çµæœä¸€è¦§','ğŸ“ˆäºˆæ¸¬çµæœ'])
            with autogluon_tab1:
                if tabular_or_multimodel=='è¡¨å½¢å¼':
                    st.write(f'è©•ä¾¡æŒ‡æ¨™ï¼š{predictor.eval_metric}')
                    train_leaderboard = st.session_state['train_leaderboard']
                    st.write(train_leaderboard)
                st.write(summary)
            with autogluon_tab2:
                st.write('äºˆæ¸¬çµæœï¼ˆæœ€å³åˆ—ã®y_predï¼‰')
                st.dataframe(test_data.assign(y_pred=y_pred))
                if tabular_or_multimodel=='è¡¨å½¢å¼':
                    test_leaderboard = st.session_state['test_leaderboard']
                    st.write('ï¼ˆå‚è€ƒï¼‰testãƒ‡ãƒ¼ã‚¿ã®çµæœ')
                    st.write(test_leaderboard)
            
            mlflow.autolog(disable=True)
            
    # H2O
    with tab5:
        st.write("H2O Flowã‚’èµ·å‹•ã—ã¦ã‹ã‚‰ã‚¯ãƒªãƒƒã‚¯â†’[ğŸ’§H2O Flow](http://localhost:54321/)")
        if st.button(label='H2O Flowã®èµ·å‹•'):
            # TODO:è¦ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼å¯¾å¿œ
            try:
                h2o.init(bind_to_localhost=False)
            except:
                h2o.init(bind_to_localhost=False)            
        if st.button(label='H2O Flowã®çµ‚äº†'):
            h2o.shutdown()

    # # auto-sklearn
    # # TODO:ä¾å­˜é–¢ä¿‚
    # with tab6:
    #     # è¨ˆç®—å®Ÿè¡Œ
    #     if st.button(label='è¨ˆç®—å®Ÿè¡Œ', key='auto-sklearn_è¨ˆç®—å®Ÿè¡Œ'):
    #         with st.spinner('auto-sklearnå®Ÿè¡Œä¸­â€¦'):
    #             # ã‚¿ã‚¹ã‚¯ã®é¸æŠ
    #             import autosklearn.classification
    #             import autosklearn.regression
    #             train, test = train_test_split(df_data, train_size=train_size, shuffle=True, random_state=0)
    #             if ml_task=='Classification':
    #                 automl = autosklearn.classification.AutoSklearnClassifier()
    #             elif ml_task=='Regression':
    #                 automl = autosklearn.regression.AutoSklearnRegressor()     
    #             else:
    #                 st.write(f"{ml_task}ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚")           
    #             automl.fit(train.drop(target_col,axis=1), train[target_col])
                
    #         # çµæœå‡ºåŠ›
    #         auto_sklearn_tab1, auto_sklearn_tab2 = st.tabs(['ğŸ“‹ï¸çµæœä¸€è¦§','ğŸ“ˆäºˆæ¸¬çµæœ'])
    #         with auto_sklearn_tab1:
    #             st.write('trainãƒ‡ãƒ¼ã‚¿ã®çµæœ')
    #             st.write(automl.leaderboard())
    #             st.write('testãƒ‡ãƒ¼ã‚¿ã®çµæœ')
    #             st.write(automl.show_models())
    #         with auto_sklearn_tab2:
    #             predictions = automl.predict(test.drop(target_col,axis=1))
    #             st.dataframe(test.assign(y_pred=y_pred))