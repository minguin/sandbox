{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KeyBERTを用いた類似説明性の付与\n",
    "https://maartengr.github.io/KeyBERT/guides/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# MODEL_NAME = \"sonoisa/sentence-luke-japanese-base-lite\"\n",
    "MODEL_NAME = \"sonoisa/sentence-bert-base-ja-mean-tokens-v2\"\n",
    "sentence_model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "金属異物の検出・除去装置を求めており、対応可能性のありそうなジェグテック登録企業14社に対してニーズを発信した。\n",
      "      \n",
      "\n",
      "粉体特性を熟知した金属異物除去装置メーカー。\n",
      "他社との違いや、自社が実現可能なこと、自社の強みを活かした提案を実施した。\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# https://jgoodtech.smrj.go.jp/pub/ja/journal/benchmark/\n",
    "# 大和化学工業株式会社\n",
    "needs_text = \"\"\"\n",
    "超高性能特殊樹脂の加工ができる企業を探しており、ジェグテックのニーズ機能にて対応できる企業を探していた。\n",
    "      \"\"\"\n",
    "seeds_text = \"\"\"\n",
    "プラスチック製品の企画・製造・販売を行う。\n",
    "顧客の様々な要望に対し、柔軟に応えられる高い技術力を持っており、本ニーズへの提案を行った。\n",
    "      \"\"\"\n",
    "\n",
    "# ハウス食品グループ本社株式会社 山伝製紙株式会社\n",
    "needs_text = \"\"\"\n",
    "SDGsの取り組みとして、新たな価値を生み出す食品残渣を活用したアップサイクルに向けたパートナー企業を探していた。\n",
    "ウコンエキスドリンク「ウコンの力」の製造過程で出るウコンの搾りかすを活用した「クルクミンの色を生かした紙の作製」のアイデアに協力してくれる企業を探していた。\n",
    "      \"\"\"\n",
    "seeds_text = \"\"\"\n",
    "伝統的な越前和紙の製造技術\n",
    "機械抄きによってさまざまな機能紙などの製造技術\n",
    "紙を抄いた上での日焼け防止の薬品コーティング技術\n",
    "      \"\"\"\n",
    "\n",
    "# ダイカテック株式会社\n",
    "needs_text = \"\"\"\n",
    "自社の持つ粉体付着防止技術（F研磨）により、「泡立ちのよいビアカップ」を開発した。\n",
    "大手飲料メーカーなどにコンタクトを取ったものの、取引に至らず試行錯誤していた。\n",
    "斬新なアイディアを求めて、ジェグテックのニーズ機能にて、商品企画パートナーを募集した。\n",
    "      \"\"\"\n",
    "seeds_text = \"\"\"\n",
    "自社でECサイトを運営し、デザイン企画・製作を手掛ける中小企業。\n",
    "アイディアのある企画をベースに、地域や企業ブランディングを得意としており、本ニーズに提案を行った。\n",
    "      \"\"\"\n",
    "\n",
    "# 株式会社イマイ\n",
    "needs_text = \"\"\"\n",
    "東南アジアへの取引拡大を目指し、東南アジアのローカル企業と出会うため、ジェグテックを活用した。\n",
    "中小機構が主催した商談会に参加し、ベトナム企業との商談を行った。\n",
    "      \"\"\"\n",
    "seeds_text = \"\"\"\n",
    "ベトナム企業（G社）：現地の食品メーカー\n",
    "ベトナム企業（H社）：商社機能を合わせ持つ、現地の食品メーカー\n",
    "      \"\"\"\n",
    "\n",
    "# ダイカテック株式会社\n",
    "needs_text = \"\"\"\n",
    "金属異物の検出・除去装置を求めており、対応可能性のありそうなジェグテック登録企業14社に対してニーズを発信した。\n",
    "      \"\"\"\n",
    "seeds_text = \"\"\"\n",
    "粉体特性を熟知した金属異物除去装置メーカー。\n",
    "他社との違いや、自社が実現可能なこと、自社の強みを活かした提案を実施した。\n",
    "      \"\"\"\n",
    "\n",
    "raw_text = f\"{needs_text}\\n{seeds_text}\"\n",
    "print(raw_text)\n",
    "\n",
    "TOP_K = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テキストを連結してキーワードを探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金属 異 ##物 の 検出 ・ 除去 装置 を 求め て おり 、 対応 可能 性 の あり そう な ジェ ##グ ##テック 登録 企業 14 社 に対して ニーズ を 発信 し た 。 粉 体 特性 を 熟 ##知 し た 金属 異 ##物 除去 装置 メーカー 。 他社 と の 違い や 、 自社 が 実現 可能 な こと 、 自社 の 強 ##み を 活かし た 提案 を 実施 し た 。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('企業 14', 0.5452),\n",
       " ('メーカー 他社', 0.5342),\n",
       " ('メーカー', 0.5188),\n",
       " ('特性 金属', 0.5093),\n",
       " ('こと 自社', 0.5067),\n",
       " ('他社 違い', 0.4916),\n",
       " ('企業', 0.4832),\n",
       " ('自社 活かし', 0.4796),\n",
       " ('違い 自社', 0.4768),\n",
       " ('装置 メーカー', 0.4688),\n",
       " ('他社', 0.4644),\n",
       " ('金属 検出', 0.4611),\n",
       " ('自社', 0.4572),\n",
       " ('金属 除去', 0.437),\n",
       " ('金属', 0.4345),\n",
       " ('ジェ テック', 0.4227),\n",
       " ('登録 企業', 0.4214),\n",
       " ('テック', 0.4142),\n",
       " ('テック 登録', 0.4002),\n",
       " ('特性', 0.396)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model = KeyBERT(model=sentence_model)\n",
    "\n",
    "# こっちで取っても可\n",
    "# from transformers import BertJapaneseTokenizer \n",
    "# tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenized_text = sentence_model.tokenizer.tokenize(raw_text)\n",
    "input_text = ' '.join(tokenized_text)\n",
    "print(input_text)\n",
    "\n",
    "keywords = kw_model.extract_keywords(\n",
    "    input_text, \n",
    "    top_n = TOP_K, \n",
    "    keyphrase_ngram_range=(1, 2)\n",
    "    )\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ニーズとシーズを分けてキーワードを探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('企業 14', 0.6349),\n",
       " ('テック 登録', 0.529),\n",
       " ('ジェ テック', 0.5218),\n",
       " ('装置 求め', 0.5047),\n",
       " ('テック', 0.4887),\n",
       " ('14 に対して', 0.487),\n",
       " ('14', 0.4771),\n",
       " ('企業', 0.4631),\n",
       " ('金属', 0.4577),\n",
       " ('金属 検出', 0.4563),\n",
       " ('ニーズ 発信', 0.4509),\n",
       " ('登録 企業', 0.4452),\n",
       " ('に対して ニーズ', 0.4353),\n",
       " ('対応 可能', 0.4297),\n",
       " ('対応', 0.3834),\n",
       " ('検出', 0.381),\n",
       " ('可能 あり', 0.3703),\n",
       " ('除去 装置', 0.37),\n",
       " ('検出 除去', 0.3674),\n",
       " ('求め おり', 0.3654)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = sentence_model.tokenizer.tokenize(needs_text)\n",
    "input_text = ' '.join(tokenized_text)\n",
    "\n",
    "keywords = kw_model.extract_keywords(\n",
    "    input_text, \n",
    "    top_n = TOP_K, \n",
    "    keyphrase_ngram_range=(1, 2), \n",
    "    seed_keywords=sentence_model.tokenizer.tokenize(seeds_text), \n",
    "#     candidates=tokenized_text, # candidatesの挙動がよくわからない\n",
    "    )\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ニーズとシーズを分けてキーワードを探す（n-gramがめんどい）\n",
    "1. needs_textの文章ベクトルを作成\n",
    "2. needs_textをTokenizeし、単語ベクトルを作成\n",
    "3. seeds_textの文章ベクトルを作成\n",
    "4. seeds_textをTokenizeし、単語ベクトルを作成\n",
    "5. 1.と4.のコサイン類似度を計算\n",
    "6. 2.と3.のコサイン類似度を計算\n",
    "7. 5.と6.の結果をよろしく結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5266, 0.5135, 0.5117, 0.5037, 0.5035, 0.4863, 0.4831, 0.4821, 0.4817,\n",
      "        0.4798, 0.4660, 0.4636, 0.4571, 0.4563, 0.4562, 0.4553, 0.4438, 0.4428,\n",
      "        0.4248, 0.4226], dtype=torch.float64),\n",
      "indices=tensor([ 4,  5,  3, 14, 17, 15,  8,  9, 16,  1,  6, 27,  2,  7, 25, 19,  0, 20,\n",
      "        13, 18]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['の',\n",
       " '検出物',\n",
       " '対応',\n",
       " 'の',\n",
       " '可能',\n",
       " '装置',\n",
       " 'を',\n",
       " '性',\n",
       " '金属',\n",
       " '・',\n",
       " '社',\n",
       " '異',\n",
       " '除去',\n",
       " '企業',\n",
       " 'そう',\n",
       " '[CLS]',\n",
       " 'な',\n",
       " '、',\n",
       " 'あり']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "import torch\n",
    "needs_output = sentence_model.encode(needs_text,output_value=None)\n",
    "needs_embeddings = needs_output['token_embeddings']\n",
    "seeds_embeddings = sentence_model.encode(seeds_text)\n",
    "\n",
    "# needs_output = sentence_model.encode(seeds_text,output_value=None)\n",
    "# needs_embeddings = needs_output['token_embeddings']\n",
    "# seeds_embeddings = sentence_model.encode(needs_text)\n",
    "\n",
    "# needs_output = sentence_model.encode(raw_text,output_value=None)\n",
    "# needs_embeddings = needs_output['token_embeddings']\n",
    "# seeds_embeddings = sentence_model.encode(raw_text)\n",
    "\n",
    "distances = 1-spatial.distance.cdist(seeds_embeddings.reshape(1,-1), needs_embeddings, 'cosine')\n",
    "results = torch.topk(torch.tensor(distances[0]), TOP_K)\n",
    "print(results)\n",
    "\n",
    "sentence_model.tokenizer.decode(needs_output['input_ids'][results.indices]).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No stoplist available in pke for 'ja' language.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['金属 異物', '除去 装置', '粉体 特性', 'ニーズ', '金属 異物 除去 装置 メーカー', '実現 可能']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pke\n",
    "\n",
    "# キーワード抽出を行う関数\n",
    "def extract_keywords(text, model_name='MultipartiteRank'):\n",
    "    if model_name=='MultipartiteRank':\n",
    "        extractor = pke.unsupervised.MultipartiteRank()\n",
    "        \n",
    "        extractor.load_document(input=text, language='ja', normalization=None)\n",
    "        extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ', 'NUM'})\n",
    "        extractor.candidate_weighting(threshold=0.74)\n",
    "        keywords = extractor.get_n_best(n=TOP_K)\n",
    "\n",
    "    if model_name=='TopicRank':\n",
    "        extractor = pke.unsupervised.TopicRank()\n",
    "        \n",
    "        extractor.load_document(input=text, language='ja', normalization=None)\n",
    "        extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ', 'NUM'})\n",
    "        extractor.candidate_weighting(threshold=0.74)\n",
    "        keywords = extractor.get_n_best(n=TOP_K)\n",
    "        \n",
    "    if model_name=='TfIdf':\n",
    "        extractor = pke.unsupervised.TfIdf()\n",
    "        \n",
    "        extractor.load_document(input=text, language='ja', normalization=None)\n",
    "        extractor.candidate_selection(n=3)\n",
    "        extractor.candidate_weighting()\n",
    "        keywords = extractor.get_n_best(n=TOP_K)\n",
    "    return [kw[0] for kw in keywords]\n",
    "\n",
    "extract_keywords(raw_text, model_name='MultipartiteRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No stoplist available in pke for 'ja' language.\n",
      "WARNING:root:LoadFile._df_counts is hard coded to c:\\Users\\tmina\\anaconda3\\lib\\site-packages\\pke\\models\\df-semeval2010.tsv.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['金属 異物',\n",
       " '除去 装置',\n",
       " '対応 可能',\n",
       " 'あり そう',\n",
       " 'ジェグテック',\n",
       " 'ジェグテック 登録',\n",
       " 'ジェグテック 登録 企業',\n",
       " '登録 企業',\n",
       " '登録 企業 14',\n",
       " '企業 14',\n",
       " 'ニーズ',\n",
       " '粉体 特性',\n",
       " '金属 異物 除去',\n",
       " '異物 除去',\n",
       " '異物 除去 装置',\n",
       " '除去 装置 メーカー',\n",
       " '装置 メーカー',\n",
       " 'メーカー',\n",
       " '実現 可能',\n",
       " '活かし']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keywords(raw_text, model_name='TfIdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'可能': 0.30499714066520933,\n",
       " '自社': 0.30499714066520933,\n",
       " '装置': 0.30499714066520933,\n",
       " '金属': 0.30499714066520933,\n",
       " '除去': 0.30499714066520933,\n",
       " '14': 0.15249857033260467,\n",
       " 'あり': 0.15249857033260467,\n",
       " 'おり': 0.15249857033260467,\n",
       " 'こと': 0.15249857033260467,\n",
       " 'そう': 0.15249857033260467,\n",
       " 'に対して': 0.15249857033260467,\n",
       " 'ジェ': 0.15249857033260467,\n",
       " 'テック': 0.15249857033260467,\n",
       " 'ニーズ': 0.15249857033260467,\n",
       " 'メーカー': 0.15249857033260467,\n",
       " '他社': 0.15249857033260467,\n",
       " '企業': 0.15249857033260467,\n",
       " '実施': 0.15249857033260467,\n",
       " '実現': 0.15249857033260467,\n",
       " '対応': 0.15249857033260467}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [' '.join(sentence_model.tokenizer.tokenize(raw_text))]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "results = torch.topk(torch.tensor(X.toarray()), TOP_K)\n",
    "dict(zip(\n",
    "    vectorizer.get_feature_names_out()[results.indices][0], \n",
    "    results.values[0].numpy()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
